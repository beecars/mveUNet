import numpy as np
import torch
from torch.utils.data import Dataset
from pathlib import Path
from utils.utils import loadMatData
from os import environ
from utils.augment import augment_ct_mask_pair

def masks2classes(masks):
    ''' 
    From multiple masks representing multiple classes, creates a single-mask 
    representation where "pixel" value is an integer class label. Input is an
    array of binary image masks, output is a single multi-class mask.
    @params:
        masks = an n-length list of mask image data
    @returns:
        a single 2D numpy array with pixel values 1-n reprensenting n classes
        from n masks
    '''
    object_class = 1
    mask_size = np.shape(masks)[1:3]
    target = np.zeros(mask_size)
    for mask in masks:
        target = target + mask * object_class
        object_class = object_class + 1
    return target

class CTMaskDataset(Dataset):
    """ A dataset for accessing a folder of 2D image data files in .npy format. 
   
    Requires a particular data folder structure:
    
        data_dir
          |--- ct                 (this structure is automatically 
          |     |--- 0.npy                 generated by "generateNpySlices()")
          |     |--- 1.npy
          |     |...
          |--- target
                |--- 0.npy
                |...
    
    Works for single-class or multi-class segmentation. 
    
    @params:
    data_dir: the path to the data_dir in the diagram above.
    """
    def __init__(self, 
                 data_dir = environ['DATA'] + '\\train_data\\',
                 plane = 'axial',
                 augment = True):
        ct_path = Path(data_dir + '/ct')
        target_path = Path(data_dir + '/target')
        self.plane = plane
        self.augment = augment
        # look for the required .npy image files
        self.ct_files = [file.__str__() for file in list(ct_path.glob('*'))]
        self.target_files = [file.__str__() for file in list(target_path.glob('*'))]
           
    def __getitem__(self, idx):
        # load up a single image/target pair into a dict 
        data_dict = {'ct': np.load(self.ct_files[idx]), 
                     'target': np.load(self.target_files[idx])
        }
        # optionally perform augmentation
        if self.augment == True: 
            data_dict = augment_ct_mask_pair(data_dict, self.plane)
        # convert to npy arrays
        for item in data_dict:
            data_dict[item] = torch.from_numpy(data_dict[item]).unsqueeze(0).float()
        # return shape is tensor(1, H, W)
        return data_dict
    
    def __len__(self):
        return len(self.ct_files)   # ct_files always populated at __init__()


class VolumeDataset(Dataset):
    """ A Dataset genereated from a [vol_idx] representing a .mat file.
    Files must have particular naming convention: 'patient1_day1.mat'

    @params:
        vol_idx: the [p, d] index to be loaded into the Dataset.
        folder: the folder containing the 'patient#_day#.mat' files.
        var: the variable to load from the .mat file (saves time?).
    """
    def __init__(self,
                 vol_idx,
                 folder = environ['DATA'] + '\\ct_pt_volumes\\',
                 var = 'ct'):
        self.ct_vol = loadMatData(vol_idx, folder, var)
       
    def __getitem__(self, idx):
        ct = torch.from_numpy(self.ct_vol[:, :, idx]).unsqueeze(0).float()
        return {'ct': ct}

    def __len__(self):
        return self.ct_vol.shape[-1]    # length is last dimension of shape
