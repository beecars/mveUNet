{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  U-Net Test: CT Bone Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import match_files_from_patient, readBinImage, readUCharImage\n",
    "from dataset import CTMaskDataset, CTPTMaskDataset\n",
    "from model import UNet\n",
    "from train import train_net, test_net\n",
    "from losses import FocalLoss, MixedLoss, dice, IoU\n",
    "\n",
    "import imgaug as iaa\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Datasets\n",
    "Get the CT and label mask files into Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_patient_idxs = [1, 2, 4, 5]\n",
    "train_dev_data = []\n",
    "for idx in train_patient_idxs:\n",
    "    for day_selection in range(1,4):\n",
    "        patient_data = match_files_from_patient(idx, day_selection, mode='CT_PT_SPINE')\n",
    "        train_dev_data.extend(patient_data)\n",
    "        \n",
    "test_patient_idxs = [3, 6]\n",
    "test_data = []\n",
    "for idx in test_patient_idxs:\n",
    "    for day_selection in range(1,4):\n",
    "        patient_data = match_files_from_patient(idx, day_selection, mode='CT_PT_SPINE')\n",
    "        test_data.extend(patient_data)\n",
    "\n",
    "seed = 544\n",
    "K = int(0.1 * len(train_dev_data))\n",
    "np.random.shuffle(train_dev_data)\n",
    "dev_data = train_dev_data[:K]\n",
    "train_data = train_dev_data[K:]\n",
    "print('train: {}, dev: {}, test: {}'.format(len(train_data), len(dev_data), len(test_data)))\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "train_dataset = CTPTMaskDataset(train_data)\n",
    "train_generator = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "dev_dataset = CTPTMaskDataset(dev_data, offset=(0,0), output_size=(512, 512), augment=False)\n",
    "dev_generator = DataLoader(dev_dataset, batch_size=batch_size, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset verification\n",
    "Check the dataset containers for correct data and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(train_dataset))\n",
    "sample_data = train_dataset[idx]\n",
    "\n",
    "ct_pt = sample_data['data']\n",
    "ct, pt = ct_pt[0, :, :], ct_pt[1, :, :]\n",
    "mask = sample_data['label']\n",
    "print(idx, ct_pt.shape, mask.shape)\n",
    "\n",
    "fig = plt.Figure(figsize=(10,20))\n",
    "ax = plt.subplot(1,2,1)\n",
    "ax.imshow(ct)\n",
    "#ax.imshow(mask, alpha=0.7, cmap='jet')\n",
    "ax.imshow(pt, alpha=0.3, cmap='jet')\n",
    "bx = plt.subplot(1,2,2)\n",
    "bx.imshow(pt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datalog folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_datetime = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "output_directory = 'logs-' + current_datetime\n",
    "if not os.path.isdir(output_directory):\n",
    "    os.makedirs(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training initialization\n",
    "Defines initial hyperparameters for learning, loss criterion, optimizer, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# model hyperparameters\n",
    "lr_model = 0.0003\n",
    "decay_step_size = 500\n",
    "gamma = 2.0\n",
    "focal_gain = 10.0\n",
    "\n",
    "# declare model\n",
    "channel_in, num_classes = 2, 1\n",
    "model = UNet(channel_in, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# learning schema\n",
    "criterion = MixedLoss(focal_gain, gamma)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_model)\n",
    "learning_scheduler = lr_scheduler.StepLR(optimizer, step_size=decay_step_size, gamma=0.1)\n",
    "\n",
    "num_epochs = 200\n",
    "ckpt_save_interval = 2\n",
    "\n",
    "# loss log initialization\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_score = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "General training scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # run training step\n",
    "    train_loss = train_net(model, \n",
    "                           device, \n",
    "                           train_generator,\n",
    "                           batch_size,\n",
    "                           criterion, \n",
    "                           optimizer,\n",
    "                           learning_scheduler,\n",
    "                           epoch, \n",
    "                           log_interval=100, \n",
    "                           print_log=True)\n",
    "\n",
    "    # run validation step\n",
    "    val_loss = test_net(model, \n",
    "                        device, \n",
    "                        dev_generator, \n",
    "                        print_log=True)\n",
    "\n",
    "    # save best models\n",
    "    if val_loss[0] > best_score:\n",
    "        best_score = val_loss[0]\n",
    "        torch.save(model.state_dict(), \n",
    "                   '{}/ckpt.model-{}.pt'.format(output_directory, epoch))\n",
    "\n",
    "    # record losses to logs\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training charts\n",
    "Not sure if this works right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores, iou_scores = zip(*val_losses)\n",
    "n = range(0, len(dice_scores))\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(n, dice_scores, label='dice')\n",
    "plt.plot(n, iou_scores, label='iou')\n",
    "plt.grid('on')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference test\n",
    "This isn't working right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = 'ckpt.model-87.pt'\n",
    "\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = UNet(2,1)\n",
    "model.load_state_dict(torch.load(ckpt_path, map_location='cpu'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "patient_idx = 9\n",
    "day_selection = 1\n",
    "\n",
    "patient_data = get_ct_pt_mask_data(patient_idx, day_selection)\n",
    "test_dataset = CTPTMaskDataset(patient_data, offset=(96, 96), output_size=(512, 512), augment=False)\n",
    "test_generator = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=10)\n",
    "\n",
    "test_loss = 0.0\n",
    "correct = 0.0\n",
    "\n",
    "spine_masks = np.zeros((len(patient_data), 512, 512))\n",
    "ct_images = np.zeros((len(patient_data), 2, 512, 512))\n",
    "with torch.no_grad():\n",
    "    for idx in range(0, len(patient_data)):\n",
    "        batch_data = test_dataset[idx]\n",
    "        ct_data = batch_data['data']\n",
    "        ct_images[idx, :, :] = ct_data\n",
    "        \n",
    "        cts = np.expand_dims(ct_data, axis=0)\n",
    "        cts = torch.from_numpy(cts).to(device)\n",
    "\n",
    "        outputs = model(cts)\n",
    "        masks_probs = torch.squeeze(F.sigmoid(outputs))\n",
    "        mask = masks_probs.cpu().numpy()\n",
    "        spine_masks[idx, :, :] = mask\n",
    "        \n",
    "scio.savemat(os.path.join(output_directory, 'test-{}-{}.mat'.format(patient_idx, day_selection)), \n",
    "             {'mask':np.transpose(spine_masks, [1, 2, 0]),\n",
    "              'ct': np.transpose(ct_images, [0, 2, 3, 1])})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}