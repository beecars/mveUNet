{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  U-Net Test: CT Bone Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import match_files_from_patient, readBinImage, readUCharImage\n",
    "from dataset import CTMaskDataset\n",
    "from model import UNet\n",
    "from train import train_net, test_net\n",
    "from losses import FocalLoss, MixedLoss, dice, IoU\n",
    "\n",
    "import imgaug as iaa\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Datasets\n",
    "Get the CT and label mask files into Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "patient_idxs = [1, 2, 3, 4, 5, 6]\n",
    "ct_data = []\n",
    "for idx in patient_idxs:\n",
    "    for day_selection in range(1,4):\n",
    "        matched_data = match_files_from_patient(idx, day_selection, mode='CT_SPINE')\n",
    "        ct_data.extend(matched_data)\n",
    "\n",
    "random.shuffle(ct_data)\n",
    "\n",
    "train_set_size = 1000\n",
    "val_set_size = int(0.2 * train_set_size)\n",
    "train_data = ct_data[0:train_set_size]\n",
    "val_data = ct_data[train_set_size:train_set_size + val_set_size]\n",
    "\n",
    "train_dataset = CTMaskDataset(train_data, augment=True)\n",
    "val_dataset = CTMaskDataset(val_data, augment=False)\n",
    "\n",
    "batch_size = 2\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset verification\n",
    "Check the dataset containers for correct data and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(train_dataset))\n",
    "sample_data = train_dataset[idx]\n",
    "\n",
    "print('data sample:')\n",
    "print(sample_data)\n",
    "\n",
    "ct = sample_data['data']\n",
    "print('ct image shape: ' + str(ct.shape))\n",
    "\n",
    "mask = sample_data['label']\n",
    "print('mask image shape: ' + str(mask.shape))\n",
    "\n",
    "fig = plt.Figure(figsize=(10,20))\n",
    "ax = plt.subplot(1,2,1)\n",
    "ax.imshow(ct[0,:,:])\n",
    "bx = plt.subplot(1,2,2)\n",
    "bx.imshow(mask[0,:,:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datalog folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime = datetime.now().strftime('%Y.%m.%d-%H.%M.%S')\n",
    "output_directory = 'trainlog-' + current_datetime\n",
    "if not os.path.isdir(output_directory):\n",
    "    os.makedirs(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training initialization\n",
    "Define hyperparameters for learning, loss function, optimizer, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# model hyperparameters\n",
    "lr_model = 0.0003\n",
    "decay_step_size = 500\n",
    "gamma = 2.0\n",
    "focal_gain = 10.0\n",
    "\n",
    "# declare model\n",
    "channel_in, num_classes = 1, 1\n",
    "model = UNet(channel_in, num_classes)\n",
    "model.to(device)\n",
    "\n",
    "# learning schema\n",
    "criterion = MixedLoss(focal_gain, gamma)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_model)\n",
    "learning_scheduler = lr_scheduler.StepLR(optimizer, step_size=decay_step_size, gamma=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "ckpt_save_interval = 2\n",
    "\n",
    "# loss log initialization\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_score = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "General training scheme with validation statistics recorded per epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # run training step\n",
    "    train_loss = train_net(model, \n",
    "                           device, \n",
    "                           train_loader,\n",
    "                           batch_size,\n",
    "                           criterion, \n",
    "                           optimizer,\n",
    "                           learning_scheduler,\n",
    "                           epoch, \n",
    "                           log_interval=100, \n",
    "                           print_log=True)\n",
    "\n",
    "    # run validation step\n",
    "    val_loss = test_net(model, \n",
    "                        device, \n",
    "                        val_loader, \n",
    "                        print_log=True)\n",
    "\n",
    "    # save best models\n",
    "    if val_loss[0] > best_score:\n",
    "        best_score = val_loss[0]\n",
    "        torch.save(model.state_dict(), \n",
    "                   '{}/ckpt.model-{}.pt'.format(output_directory, epoch))\n",
    "\n",
    "    # record losses to logs\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training charts\n",
    "Not sure if this works right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores, iou_scores = zip(*val_losses)\n",
    "n = range(0, len(dice_scores))\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(n, dice_scores, label='dice')\n",
    "plt.plot(n, iou_scores, label='iou')\n",
    "plt.grid('on')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference test\n",
    "This isn't working right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}